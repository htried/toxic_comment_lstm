# toxic_comment_lstm

A project undertaken for Brown University's Wintersession class "Deep Learning in Minds, Brains, and Machines." Going off of some of the best practices found on a Kaggle competition, we designed several language processing neural networks based off of LSTMs and Naive Bayesian analysis. These were employed upon a dataset of Wikipedia comments to identify and learn a model of a toxic online commenting, achieving accuracies in the mid- to high-90th percentile. Also contained in this repository is a toy REPL program that takes in command line input and tells you its toxicity and a toxic comment generator that takes in a set of comments and uses character embeddings to output similar text.

All data for the project can be found at https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge.
